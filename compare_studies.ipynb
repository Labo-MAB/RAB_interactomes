{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "import gzip\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2\n",
    "import Bio.UniProt.GOA as gafiterator\n",
    "\n",
    "from utils import colname_to_mi, get_orthologs, defaultdict_to_regular, get_go_terms, plot_upset\n",
    "\n",
    "# ignore warnings pandas for groubpy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rab name conversion to match the Rab names in Jean dataset. \n",
    "# Matched name according to this list: https://www.genenames.org/data/genegroup/#!/group/388\n",
    "rab_conversion = {\n",
    "                    'RAB1A': 'RAB1',\n",
    "                    'RAB2A': 'RAB2',\n",
    "                    'RAB7A': 'RAB7',\n",
    "                    'RAB9A': 'RAB9',\n",
    "                    'RAB11A': 'RAB11',\n",
    "                    'RAB27A': 'RAB27',\n",
    "                    'RAB4A': 'RAB4',\n",
    "                    'RAB5A': 'RAB5',\n",
    "                    'RAB5B': 'RAB5',\n",
    "                    'RAB5C': 'RAB5',\n",
    "                    'RAB6A': 'RAB6'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and cleaning datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Files path\n",
    "\n",
    "# Datasets\n",
    "JEAN = 'data/SAINT Analysis 2-3 repeats-Organized.xlsx'\n",
    "GILLINGHAM2019 = 'data/elife-45916-supp1-v2.xlsx'\n",
    "GILLINGHAM2014 = 'data/mmc2.xlsx'\n",
    "LI = 'data/mmc3.xlsx'\n",
    "WILSON = 'data/wilson.tsv'\n",
    "\n",
    "# Orthologs lists\n",
    "GILLINGHAM2014_INT_ORTHOLOGS = 'data/orthologs/gillingham2014_interactors_orthologs.xlsx'\n",
    "GILLINGHAM2014_BAIT_ORTHOLOGS = 'data/orthologs/gillingham2014_baits_orthologs.xlsx'\n",
    "LI_INT_ORTHOLOGS = 'data/orthologs/li2016_interactors_orthologs.xlsx'\n",
    "LI_BAIT_ORTHOLOGS = 'data/orthologs/li2016_baits_orthologs.xlsx'\n",
    "\n",
    "# Figures output\n",
    "INTERACTORS_COMPARISON = lambda type_: f'figures/genes_comparison_{type_}.svg'  # type_ = 'strict' or 'total' (intersection type)\n",
    "GO_TERMS_COMPARISON = lambda cat: f'figures/GOterms_{cat}.svg' # cat = 'cellular_component', 'biological_process' or 'molecular_function'\n",
    "RANDOM_INTERACTORS = lambda type_: f'figures/random_genes_comparison_{type_}.svg'\n",
    "GO_TERMS_RANDOM_COMPARISON = lambda cat: f'figures/random_GOterms_{cat}.svg'\n",
    "GO_ANNOTATED_GENES = 'figures/GO-annotated_genes.svg'\n",
    "\n",
    "# GO terms\n",
    "OBO = 'data/GOA/go-basic.obo'\n",
    "GAF = lambda species: f'data/GOA/goa_{species}.gaf.gz' # species = 'human', 'mouse', 'fly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Jean et al.\n",
    "\n",
    "saint_threshold = 0.95\n",
    "\n",
    "jean_raw = pd.read_excel(JEAN, sheet_name='SAINT Analysis 2-3 repeats', usecols=['Bait', 'Prey', 'AvgSpec', 'SaintScore'])\n",
    "jean_raw['Bait'] = jean_raw['Bait'].str.replace('R', 'RAB') # Change name to match other datasets\n",
    "jean = jean_raw[jean_raw['SaintScore'] > saint_threshold] # Filter out low confidence interactions\n",
    "jean = jean.pivot_table(index='Prey', columns='Bait', values='AvgSpec')\n",
    "jean.index = jean.index.str.upper()\n",
    "jean.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gillingham et al. (2019)\n",
    "\n",
    "wd_threshold = 10\n",
    "\n",
    "gill2019 = pd.read_excel(GILLINGHAM2019, skiprows=range(1,8), header=1, sheet_name='Spectral counts')\n",
    "gill2019.index = gill2019['Gene Name'].str.upper()\n",
    "\n",
    "# Filter out non-rab columns and convert colnames to multiindex\n",
    "gill2019 = gill2019[[col for col in gill2019.columns if re.match(r'Rab\\d+', col)]]\n",
    "new_colnames = [colname_to_mi(col) for col in gill2019.columns]\n",
    "gill2019.columns = pd.MultiIndex.from_tuples(new_colnames)\n",
    "gill2019 = gill2019.groupby(level=[0,1], axis=1).sum()\n",
    "\n",
    "# Get WD scores to filter out low confidence interactions\n",
    "gill2019_wd_scores = pd.read_excel(GILLINGHAM2019, skiprows=range(1,8), header=1, sheet_name='Mean WD Score')\n",
    "gill2019_wd_scores.index = gill2019_wd_scores['Gene Name'].str.upper()\n",
    "gill2019_wd_scores = gill2019_wd_scores[[col for col in gill2019_wd_scores.columns if re.match(r'Rab\\d+', col)]]\n",
    "new_colnames = [tuple(colname.split('  ')) for colname in gill2019_wd_scores.columns]\n",
    "gill2019_wd_scores.columns = pd.MultiIndex.from_tuples(new_colnames)\n",
    "\n",
    "# If WD < threshold, set spectral counts to 0\n",
    "gill2019 = gill2019.where(gill2019_wd_scores > wd_threshold, other=0)\n",
    "gill2019 = gill2019[gill2019.sum(axis=1) > 0] # Remove rows with no spectral counts\n",
    "\n",
    "# Sum GTP-locked and GDP-locked forms\n",
    "gill2019 = gill2019.groupby(level=0, axis=1).sum()\n",
    "gill2019.columns = gill2019.columns.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gillingham et al. (2014)\n",
    "\n",
    "threshold = 5\n",
    "\n",
    "gill2014 = pd.read_excel(GILLINGHAM2014, skiprows=range(1, 8), header=1,\n",
    "                         sheet_name='S1A - Total Spectral Counts')\n",
    "# gill2014.index = gill2014['FBgn']\n",
    "gill2014.index = gill2014['Symbol']\n",
    "\n",
    "# Filter baits other than Rabs\n",
    "usecols = [col for col in gill2014.columns if re.match(r'Rab\\d+', col)]\n",
    "gill2014 = gill2014[usecols]\n",
    "\n",
    "# Load score to filter out low confidence interactors\n",
    "gill2014_scores = pd.read_excel(GILLINGHAM2014, skiprows=range(1, 8), header=1,\n",
    "                                sheet_name='S1B - S scores')\n",
    "gill2014_scores.index = gill2014_scores['Symbol']\n",
    "usecols = [col for col in gill2014_scores.columns if re.match(r'Rab\\d+', col)]\n",
    "gill2014_scores = gill2014_scores[usecols]\n",
    "gill2014_scores.columns = gill2014_scores.columns.str.upper()\n",
    "\n",
    "\n",
    "# Chang bait names for their human orthologs names and format it to match Jean's dataset\n",
    "gill_baits_orthologs = get_orthologs(GILLINGHAM2014_BAIT_ORTHOLOGS)\n",
    "gill2014.columns = gill2014.columns.map(gill_baits_orthologs)\n",
    "gill2014.columns = [\n",
    "    rab_conversion[rab] if rab in rab_conversion else rab for rab in gill2014.columns\n",
    "]\n",
    "\n",
    "# Filter out low confidence interactors\n",
    "gill2014 = gill2014.where(gill2014_scores > threshold, other=0)\n",
    "gill2014 = gill2014[gill2014.sum(axis=1) > 0] # Remove rows with no spectral counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Li et al. (2016)\n",
    "li = pd.read_excel(LI, skiprows=1, header=0, sheet_name='Bait-prey information')\n",
    "li = li.pivot_table(index=['Official Symbol'], columns=['Bait'], values='Average Spectal Counts')\n",
    "\n",
    "# Change mouse rab names for their human orthologs names and format it to match Jean's dataset\n",
    "li_bait_orthologs = get_orthologs(LI_BAIT_ORTHOLOGS)\n",
    "li.columns = li.columns.map(li_bait_orthologs)\n",
    "li.columns = [\n",
    "    rab_conversion[rab] if rab in rab_conversion else rab for rab in li.columns\n",
    "    ]\n",
    "li.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing our study with Gillingham et al. (2014 and 2019) and Li et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Rab which are common to all datasets\n",
    "common = list(set.intersection(\n",
    "    *map(set, [jean.columns, gill2019.columns, gill2014.columns, li.columns])\n",
    "))\n",
    "\n",
    "# Clean datasets from RAB not common to all datasets\n",
    "filter_df = lambda df, common: df[df[common].sum(axis=1) != 0]\n",
    "\n",
    "jean = filter_df(jean, common)\n",
    "gill2019 = filter_df(gill2019, common)\n",
    "gill2014 = filter_df(gill2014, common)\n",
    "li = filter_df(li, common)\n",
    "\n",
    "common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactors across studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Li and Gillingham 2014 gene names to their human orthologs\n",
    "\n",
    "## Gillingham et al. (2014)\n",
    "gill_int_orthologs = get_orthologs(GILLINGHAM2014_INT_ORTHOLOGS)\n",
    "gill2014_orthologs = gill2014[gill2014.index.isin(gill_int_orthologs)]  # Remove genes with no human orthologs\n",
    "gill2014_orthologs.index = gill2014_orthologs.index.map(gill_int_orthologs).str.upper()   # Change gene names to human orthologs\n",
    "\n",
    "## Li et al. (2016)\n",
    "li_int_orthologs = get_orthologs(LI_INT_ORTHOLOGS)\n",
    "li_orthologs = li[li.index.isin(li_int_orthologs)]  # Remove genes with no human orthologs\n",
    "li_orthologs.index = li_orthologs.index.map(li_int_orthologs).str.upper()  # Change gene names to human orthologs\n",
    "\n",
    "print(f'{len(gill2014) - len(gill2014_orthologs)} rows on {len(gill2014)} removed from Gillingham 2014 dataset due to lack of human orthologs')\n",
    "print(f'{len(li) - len(li_orthologs)} row on {len(li)} removed from Li dataset due to lack of human orthologs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dict of datasets for simpler data handling\n",
    "genes_datasets = {'This study': jean,\n",
    "                  'Gillingham et al. (2019)': gill2019,\n",
    "                  'Gillingham et al. (2014)': gill2014_orthologs,\n",
    "                  'Li et al. (2016)': li_orthologs}\n",
    "\n",
    "# Plot upset of common interactors\n",
    "genes_data = {dataset: list(np.unique(df.index.tolist())) for dataset, df in genes_datasets.items()}\n",
    "\n",
    "fig = plot_upset(genes_data, intersection_type='total')\n",
    "# plt.savefig(INTERACTORS_COMPARISON('total'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GO analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If GO terms and GO annotations are not downloaded, download them\n",
    "if len(os.listdir('data/GOA')) == 0:\n",
    "    from download_GO import download\n",
    "    download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all interactors to extract GO terms from annotations\n",
    "interactors = {'human': list(jean.index.tolist() + \\\n",
    "                             gill2019.index.tolist() + \\\n",
    "                             gill2014_orthologs.index.tolist()),\n",
    "               'mouse': li.index.tolist(),\n",
    "               'fly': gill2014.index.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict to store Go id for each interactors for each GO term category\n",
    "goa = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "\n",
    "# Get GO annotations for the identified interactors\n",
    "for species, interacts in interactors.items():\n",
    "    with gzip.open(GAF(species), 'rt') as f:\n",
    "        for annotation in gafiterator.gafiterator(f):\n",
    "            if annotation['DB_Object_Symbol'] not in interacts:\n",
    "                continue\n",
    "            \n",
    "            aspect = annotation['Aspect']\n",
    "            symbol = annotation['DB_Object_Symbol']\n",
    "            if annotation['GO_ID'] not in goa[species][aspect][symbol]:\n",
    "                goa[species][aspect][symbol].append(annotation['GO_ID'])\n",
    "                \n",
    "goa = defaultdict_to_regular(goa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract GO terms for each dataset and each GO terms category and make an upset plot\n",
    "go_categories = {\n",
    "        # 'F': 'molecular_function',\n",
    "        # 'C': 'cellular_component',\n",
    "        'P': 'biological_process'\n",
    "        }\n",
    "\n",
    "for category in go_categories:\n",
    "    go_data = {\n",
    "            'This study': get_go_terms(goa['human'][category], jean.index),\n",
    "            'Gillingham et al. (2019)': get_go_terms(goa['human'][category], gill2019.index),\n",
    "            'Gillingham et al. (2014) *orthologs': get_go_terms(goa['human'][category], gill2014_orthologs.index),\n",
    "            'Li et al. (2016)': get_go_terms(goa['mouse'][category], li.index),\n",
    "            }\n",
    "    \n",
    "    fig = plot_upset(go_data, title=go_categories[category])\n",
    "#     plt.savefig(GO_TERMS_COMPARISON(go_categories[category]), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing our study with Wilson et al., 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Jean et al.\n",
    "\n",
    "saint_threshold = 0.95\n",
    "\n",
    "jean_raw = pd.read_excel(JEAN, sheet_name='SAINT Analysis 2-3 repeats', usecols=['Bait', 'Prey', 'AvgSpec', 'SaintScore'])\n",
    "jean_raw['Bait'] = jean_raw['Bait'].str.replace('R', 'RAB') # Change name to match other datasets\n",
    "jean = jean_raw[jean_raw['SaintScore'] > saint_threshold] # Filter out low confidence interactions\n",
    "jean = jean.pivot_table(index='Prey', columns='Bait', values='AvgSpec')\n",
    "jean.index = jean.index.str.upper()\n",
    "jean.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Wilson et al. (2023)\n",
    "saint_threshold = 0.95\n",
    "\n",
    "wilson_raw = pd.read_csv(WILSON, sep='\\t')\n",
    "wilson = wilson_raw[wilson_raw['SaintScore'] > saint_threshold] # Filter out low confidence interactions\n",
    "wilson = wilson.pivot_table(index='Prey', columns='Bait', values='AvgSpec')\n",
    "wilson.index = wilson.index.str.upper()\n",
    "wilson.columns = [\n",
    "    rab_conversion[rab] if rab in rab_conversion else rab for rab in wilson.columns\n",
    "]\n",
    "wilson.fillna(0, inplace=True)\n",
    "\n",
    "# Extract gene ids and gene names for gaf file to convert Wilson identification\n",
    "columns = [\n",
    "    'db', 'id', 'symbol', 'qualifier', 'go_id', 'db_reference', 'evidence_code',\n",
    "    'with_from', 'aspect', 'db_object_name', 'db_object_synonym', 'db_object_type',\n",
    "    'taxon', 'date', 'assigned_by' 'annotation_extension', 'gene_product_form_id'\n",
    "]\n",
    "gaf = pd.read_csv(GAF('human'), sep='\\t', comment='!', index_col=False, names=columns)\n",
    "\n",
    "\n",
    "name_mapper = dict(zip(gaf['id'], gaf['symbol']))\n",
    "\n",
    "wilson.index = wilson.index.map(name_mapper).str.upper()\n",
    "print(wilson.index.isna().sum(), \"gene ids could not be mapped to gene names\")\n",
    "wilson.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactors across studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Rab which are common to all datasets\n",
    "common = list(set.intersection(\n",
    "    *map(set, [jean.columns, wilson.columns])\n",
    "))\n",
    "\n",
    "jean = jean[jean[common].sum(axis=1) != 0][common]\n",
    "wilson = wilson[wilson[common].sum(axis=1) != 0][common]\n",
    "\n",
    "common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jean.index.shape[0], \"different interactors were identified in Jean dataset\")\n",
    "print(wilson.index.shape[0], \"different interactors were identified in Wilson dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dict of datasets for simpler data handling\n",
    "genes_datasets = {\n",
    "    'This study': jean,\n",
    "    'Wilson et al. (2023)': wilson\n",
    "}\n",
    "\n",
    "# Plot upset of common interactors\n",
    "genes_data = {\n",
    "    \"This study\": {\n",
    "        \"Rab4\": jean.index[jean['RAB4'].astype(bool)].unique().values,\n",
    "        \"Rab11\": jean.index[jean['RAB11'].astype(bool)].unique().values,\n",
    "        \"Rab25\": jean.index[jean['RAB25'].astype(bool)].unique().values,\n",
    "    },\n",
    "    \"Wilson et al.\" : {\n",
    "        \"Rab4\": wilson.index[wilson['RAB4'].astype(bool)].unique().values,\n",
    "        \"Rab11\": wilson.index[wilson['RAB11'].astype(bool)].unique().values,\n",
    "        \"Rab25\": wilson.index[wilson['RAB25'].astype(bool)].unique().values\n",
    "        \n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All interactors Venn diagram\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "venn2(\n",
    "      (\n",
    "            set([interactor for interactors in genes_data['This study'].values() for interactor in interactors]),\n",
    "            set([interactor for interactors in genes_data['Wilson et al.'].values() for interactor in interactors])\n",
    "      ),\n",
    "      set_labels=('This study', 'Wilson et al.'),\n",
    "      set_colors=('#709B92', '#a84c4cff'),\n",
    "      ax=ax,\n",
    ")\n",
    "fig.suptitle(\"All baits\", y=0.9, fontsize=16)\n",
    "# fig.savefig('figures/wilson_all_interactors.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 6))\n",
    "\n",
    "# Get the maximum number of interactors in a category for normalization\n",
    "num_interactors = []\n",
    "for bait in genes_data['This study']:\n",
    "    num = set(genes_data['This study'][bait]).union(set(genes_data['Wilson et al.'][bait]))\n",
    "    num_interactors.append(len(num))\n",
    "max_num_interactors = max(num_interactors)\n",
    "\n",
    "ax_pos = [(0, 0), (0, 1), (1, 0)]\n",
    "for bait, pos in zip(genes_data['This study'], ax_pos):\n",
    "    ax = axes[pos]\n",
    "\n",
    "    # Get the normalization value to have the same scale on each venn diagram\n",
    "    actual_num_interactors = len(set(genes_data['This study'][bait]).union(set(genes_data['Wilson et al.'][bait])))\n",
    "    normalize_to = np.sqrt(max_num_interactors / actual_num_interactors)\n",
    "    genes_data['This study'][bait] = [gene for gene in genes_data['This study'][bait] if gene != '']\n",
    "    venn2(\n",
    "        (\n",
    "            set(genes_data['This study'][bait]),\n",
    "            set(genes_data['Wilson et al.'][bait])\n",
    "        ),\n",
    "        set_labels=('This study', 'Wilson et al.'),\n",
    "        set_colors=('#709B92', '#a84c4cff'),\n",
    "        ax=ax,\n",
    "        # layout_algorithm=LayoutAlgorithm(normalize_to=normalize_to),\n",
    "    )\n",
    "    ax.set_xlim(-normalize_to, normalize_to)\n",
    "    ax.set_ylim(-normalize_to, normalize_to)\n",
    "    ax.set_title(bait)\n",
    "\n",
    "axes[1, 1].axis('off')  # Hide the last subplot\n",
    "\n",
    "# fig.savefig('figures/wilson_interactors_by_bait.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GO analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all interactors to extract GO terms from annotations\n",
    "interactors = {\n",
    "    'human': jean.index.tolist() + wilson.index.tolist(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict to store Go id for each interactors for each GO term category\n",
    "goa = defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "\n",
    "# Get GO annotations for the identified interactors\n",
    "for species, interacts in interactors.items():\n",
    "    with gzip.open(GAF(species), 'rt') as f:\n",
    "        for annotation in gafiterator.gafiterator(f):\n",
    "            if annotation['DB_Object_Symbol'] not in interacts:\n",
    "                continue\n",
    "            \n",
    "            aspect = annotation['Aspect']\n",
    "            symbol = annotation['DB_Object_Symbol']\n",
    "            if annotation['GO_ID'] not in goa[species][aspect][symbol]:\n",
    "                goa[species][aspect][symbol].append(annotation['GO_ID'])\n",
    "                \n",
    "goa = defaultdict_to_regular(goa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract GO terms for each dataset and each GO terms category and make an upset plot\n",
    "go_categories = {\n",
    "        'F': 'molecular_function',\n",
    "        'C': 'cellular_component',\n",
    "        'P': 'biological_process'\n",
    "        }\n",
    "\n",
    "# Get GO terms for each dataset and each GO terms category\n",
    "go_data = {}\n",
    "for category, category_name in go_categories.items():\n",
    "    go_data[category_name] = {\n",
    "            \"This study\": {\n",
    "                \"Rab4\": get_go_terms(\n",
    "                    goa['human'][category], jean.index[jean['RAB4'].astype(bool)].unique().values\n",
    "                    ),\n",
    "                \"Rab11\": get_go_terms(\n",
    "                    goa['human'][category], jean.index[jean['RAB11'].astype(bool)].unique().values\n",
    "                ),\n",
    "                \"Rab25\": get_go_terms(\n",
    "                    goa['human'][category], jean.index[jean['RAB25'].astype(bool)].unique().values\n",
    "                ),\n",
    "            },\n",
    "            \"Wilson et al.\": {\n",
    "                \"Rab4\": get_go_terms(\n",
    "                    goa['human'][category], wilson.index[wilson['RAB4'].astype(bool)].unique().values\n",
    "                ),\n",
    "                \"Rab11\": get_go_terms(\n",
    "                    goa['human'][category], wilson.index[wilson['RAB11'].astype(bool)].unique().values\n",
    "                ),\n",
    "                \"Rab25\": get_go_terms(\n",
    "                    goa['human'][category], wilson.index[wilson['RAB25'].astype(bool)].unique().values\n",
    "                )\n",
    "            }\n",
    "            \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare GO terms between studies (independantly of the bait)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "ax_pos = [(0, 0), (0, 1), (1, 0)]\n",
    "\n",
    "# Get maximum number of GO terms in a category for normalization\n",
    "num_go_terms = []\n",
    "for category in go_data:\n",
    "    num = 0\n",
    "    for bait in go_data[category]['This study']:\n",
    "        num += len(set(go_data[category]['This study'][bait]).union(set(go_data[category]['Wilson et al.'][bait])))\n",
    "    num_go_terms.append(num)\n",
    "max_num_go_terms = max(num_go_terms)\n",
    "\n",
    "for category, pos in zip(go_data.keys(), ax_pos):\n",
    "    data = go_data[category]\n",
    "    ax = axes[pos]\n",
    "\n",
    "    jean_go = []\n",
    "    wilson_go = []\n",
    "    for bait in data[\"This study\"]:\n",
    "        jean_go.extend(data['This study'][bait])\n",
    "        wilson_go.extend(data['Wilson et al.'][bait])\n",
    "        \n",
    "    # Get the normalization value to have the same scale on each venn diagram\n",
    "    actual_num_go = len(set(jean_go).union(set(wilson_go)))\n",
    "    normalize_to = np.sqrt(max_num_go_terms / actual_num_go) * 0.75 # Adjusted for better visualization\n",
    "    venn2(\n",
    "        (\n",
    "            set(jean_go),\n",
    "            set(wilson_go)\n",
    "        ),\n",
    "        set_labels=('This study', 'Wilson et al.'),\n",
    "        set_colors=('#709B92', '#a84c4cff'),\n",
    "        ax=ax,\n",
    "        # layout_algorithm=LayoutAlgorithm(normalize_to=normalize_to),\n",
    "    )\n",
    "    ax.set_xlim(-normalize_to, normalize_to)\n",
    "    ax.set_ylim(-normalize_to, normalize_to)\n",
    "    ax.set_title(category)\n",
    "\n",
    "axes[1, 1].axis('off')  # Hide the last subplot\n",
    "# fig.savefig('figures/wilson_go_terms.svg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
